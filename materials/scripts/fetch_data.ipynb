{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae98481e",
   "metadata": {},
   "source": [
    "## Setting Up Alpaca API Access\n",
    "\n",
    "__Before__ executing the codes, follow the steps below to set up your Alpaca API credentials for accessing financial news and stock price data.\n",
    "\n",
    "### 1. Create an Alpaca API Account\n",
    "\n",
    "Refer to the [`Creating_an_Alpaca_API_Account.pdf`] file in the `materials/` folder for instructions on creating your Alpaca account.\n",
    "\n",
    "You will need to obtain:\n",
    "\n",
    "- **API Key ID**\n",
    "- **Secret Key**\n",
    "\n",
    "These credentials are necessary for connecting to the Alpaca API and retrieving financial data.\n",
    "\n",
    "### 2. Store Your Credentials in a `.env` File\n",
    "\n",
    "Once you have your API credentials:\n",
    "\n",
    "1. Go to the `materials/` folder in your project directory.\n",
    "2. Create a new file named `.env` (e.g., `materials/.env`).\n",
    "3. Add the following lines to the `.env` file, replacing the placeholders with your actual credentials:\n",
    "\n",
    "    ```.env\n",
    "    APCA_API_KEY_ID=your_alpaca_key_id_here\n",
    "    APCA_API_SECRET_KEY=your_alpaca_secret_key_here\n",
    "    ```\n",
    "\n",
    "> **Important:** Keep your `.env` file secure. Do **not** upload it to public repositories. Make sure to add `.env` to your `.gitignore` file to prevent accidental exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29926de8",
   "metadata": {},
   "source": [
    "### Fetch financial news headlines and summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a28b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for 2025-01-06...\n",
      "Fetching news for 2025-01-07...\n",
      "Fetching news for 2025-01-08...\n",
      "Fetching news for 2025-01-09...\n",
      "Fetching news for 2025-01-10...\n",
      "Fetching news for 2025-01-11...\n",
      "Fetching news for 2025-01-12...\n",
      "Fetching news for 2025-01-13...\n",
      "Fetching news for 2025-01-14...\n",
      "Fetching news for 2025-01-15...\n",
      "Fetching news for 2025-01-16...\n",
      "Fetching news for 2025-01-17...\n",
      "Fetching news for 2025-01-18...\n",
      "Fetching news for 2025-01-19...\n",
      "Fetching news for 2025-01-20...\n",
      "Fetching news for 2025-01-21...\n",
      "Fetching news for 2025-01-22...\n",
      "Fetching news for 2025-01-23...\n",
      "Fetching news for 2025-01-24...\n",
      "Fetching news for 2025-01-25...\n",
      "Fetching news for 2025-01-26...\n",
      "Fetching news for 2025-01-27...\n",
      "Fetching news for 2025-01-28...\n",
      "Fetching news for 2025-01-29...\n",
      "Fetching news for 2025-01-30...\n",
      "Fetching news for 2025-01-31...\n",
      "Fetching news for 2025-02-01...\n",
      "Fetching news for 2025-02-02...\n",
      "Fetching news for 2025-02-03...\n",
      "Fetching news for 2025-02-04...\n",
      "Fetching news for 2025-02-05...\n",
      "Fetching news for 2025-02-06...\n",
      "Fetching news for 2025-02-07...\n",
      "Fetching news for 2025-02-08...\n",
      "Fetching news for 2025-02-09...\n",
      "Fetching news for 2025-02-10...\n",
      "Fetching news for 2025-02-11...\n",
      "Fetching news for 2025-02-12...\n",
      "Fetching news for 2025-02-13...\n",
      "Fetching news for 2025-02-14...\n",
      "Fetching news for 2025-02-15...\n",
      "Fetching news for 2025-02-16...\n",
      "Fetching news for 2025-02-17...\n",
      "Fetching news for 2025-02-18...\n",
      "Fetching news for 2025-02-19...\n",
      "Fetching news for 2025-02-20...\n",
      "Fetching news for 2025-02-21...\n",
      "Fetching news for 2025-02-22...\n",
      "Fetching news for 2025-02-23...\n",
      "Fetching news for 2025-02-24...\n",
      "Fetching news for 2025-02-25...\n",
      "Fetching news for 2025-02-26...\n",
      "Fetching news for 2025-02-27...\n",
      "Fetching news for 2025-02-28...\n",
      "Saved news for 54 days to ../data/nvda_news.csv\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# load Alpaca API credential from the .env file\n",
    "API_KEY = os.getenv(\"APCA-API-KEY-ID\")\n",
    "API_SECRET = os.getenv(\"APCA-API-SECRET-KEY\")\n",
    "\n",
    "# define constants for API access\n",
    "BASE_URL = \"https://data.alpaca.markets/v1beta1/news\" # Alpaca news endpoint\n",
    "SYMBOL = \"NVDA\" # target stock symbol\n",
    "LIMIT = 50  # max news articles per request\n",
    "\n",
    "\n",
    "def fetch_news_for_date(date_str):\n",
    "    \"\"\"\n",
    "    Fetch news articles for a specific date.\n",
    "    Args:\n",
    "        date_str (str): date in 'YYYY-MM-DD' format.\n",
    "    Returns:\n",
    "        list: a list of news articles for the specified date.\n",
    "    \"\"\"\n",
    "\n",
    "    # define start and end times for the entire day\n",
    "    start = f\"{date_str}T00:00:00Z\"\n",
    "    end = f\"{date_str}T23:59:59Z\"\n",
    "\n",
    "    # construct API request URL with query parameters\n",
    "    url = f\"{BASE_URL}?symbols={SYMBOL}&start={start}&end={end}&limit={LIMIT}\"\n",
    "\n",
    "    # prepare request headers with Alpaca API credentials\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"APCA-API-KEY-ID\": API_KEY,\n",
    "        \"APCA-API-SECRET-KEY\": API_SECRET\n",
    "    }\n",
    "\n",
    "    # make GET request to the Alpaca API\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # check for a successful response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch news for {date_str}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # return the list of news articles\n",
    "    return response.json().get(\"news\", [])\n",
    "\n",
    "\n",
    "def save_news_to_csv(start_date_str, end_date_str, output_path=\"../data/nvda_news.csv\"):\n",
    "    \"\"\"\n",
    "    Compile news headline and summary from a date range and saves it to a CSV file.\n",
    "    Args:\n",
    "        start_date_str (str): start date in 'YYYY-MM-DD' format.\n",
    "        end_date_str (str): end date in 'YYYY-MM-DD' format.\n",
    "        output_path (str): path to save the output CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    all_news = []\n",
    "\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "        print(f\"Fetching news for {date_str}...\")\n",
    "\n",
    "        # fetch news for the current date\n",
    "        daily_news = fetch_news_for_date(date_str)\n",
    "\n",
    "        content_list = []\n",
    "        for item in daily_news:\n",
    "\n",
    "            # clean and collect headline and summary\n",
    "            headline = item.get(\"headline\", \"\").replace(\"\\n\", \" \").strip()\n",
    "            summary = item.get(\"summary\", \"\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "            if headline:\n",
    "                content_list.append(headline)\n",
    "            if summary:\n",
    "                content_list.append(summary)\n",
    "\n",
    "        # add date and content list (as JSON string) to result\n",
    "        all_news.append({\n",
    "            \"date\": date_str,\n",
    "            \"content\": json.dumps(content_list)  # Store as JSON string for proper list format\n",
    "        })\n",
    "\n",
    "        # move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # write collected news data to CSV\n",
    "    with open(output_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=[\"date\", \"content\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_news)\n",
    "\n",
    "    print(f\"Saved news for {len(all_news)} days to {output_path}\")\n",
    "\n",
    "# execute news aggregation function for a given date range\n",
    "save_news_to_csv(\"2025-01-06\", \"2025-02-28\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e4a42",
   "metadata": {},
   "source": [
    "### Fetch stock open price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7145e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 37 entries to ../data/nvda_open_prices.csv\n"
     ]
    }
   ],
   "source": [
    "# reload environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def build_url(start_date, end_date, symbol=\"NVDA\", timeframe=\"1D\", limit=1000):\n",
    "    \"\"\"\n",
    "    Build the URL for Alpaca historical bar data.\n",
    "    Args:\n",
    "        start_date (str): start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): end date in 'YYYY-MM-DD' format.\n",
    "        symbol (str): stock symbol.\n",
    "        timeframe (str): time interval (e.g., '1D' for daily).\n",
    "        limit (int): max number of records to fetch.\n",
    "    Returns:\n",
    "        str: a fully formatted API request URL.\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = f\"https://data.alpaca.markets/v2/stocks/{symbol}/bars\"\n",
    "    return f\"{base_url}?timeframe={timeframe}&start={start_date}&end={end_date}&limit={limit}\"\n",
    "\n",
    "\n",
    "def get_opening_prices(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Retrieves the daily opening prices for a given stock over a date range.\n",
    "    Args:\n",
    "        start_date (str): start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): end date in 'YYYY-MM-DD' format.\n",
    "    Returns:\n",
    "        list: a list of dictionaries with date and opening price.\n",
    "    \"\"\"\n",
    "\n",
    "    url = build_url(start_date, end_date)\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"APCA-API-KEY-ID\": os.getenv(\"APCA-API-KEY-ID\"),\n",
    "        \"APCA-API-SECRET-KEY\": os.getenv(\"APCA-API-SECRET-KEY\")\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    bar_data = response.json().get(\"bars\", [])\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            \"date\": bar[\"t\"].split(\"T\")[0],  # extract date part only from timestamp\n",
    "            \"open_price\": bar[\"o\"]\n",
    "        }\n",
    "        for bar in bar_data\n",
    "    ]\n",
    "\n",
    "\n",
    "def save_open_prices_to_csv(start_date, end_date, output_path=\"../data/nvda_open_prices.csv\"):\n",
    "    \"\"\"\n",
    "    Fetches opening prices for a stock and saves them to a CSV file.\n",
    "    Args:\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        output_path (str): File path for the output CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    data = get_opening_prices(start_date, end_date)\n",
    "\n",
    "    if not data:\n",
    "        print(\"No data found.\")\n",
    "        return\n",
    "\n",
    "    with open(output_path, mode=\"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"date\", \"open_price\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Saved {len(data)} entries to {output_path}\")\n",
    "\n",
    "# execute function to save opening prices\n",
    "save_open_prices_to_csv(\"2025-01-06\", \"2025-02-28\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
