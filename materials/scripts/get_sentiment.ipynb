{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0aea7e",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using VADER\n",
    "This notebook performs sentiment analysis on financial news headlines and summaries related to a specific stock (e.g., NVDA). The analysis is broken into two major steps:\n",
    "\n",
    "### 1. Aggregating News to Trading Days\n",
    "Stock markets are closed on weekends and holidays, but financial news is often published daily. To reflect investor behavior, where decisions are made when the market reopens, news from non-trading days is aggregated and assigned to the next trading day. This provides a more accurate mapping between sentiment and stock movement.\n",
    "\n",
    "### 2. Analyzing Sentiment with VADER\n",
    "Sentiment analysis is performed using __VADER__ (Valence Aware Dictionary and sEntiment Reasoner), a rule-based tool designed specifically for short texts such as headlines and social media posts. Although it is not machine-learning based, VADER is highly effective at capturing the nuances of informal language, including slang, emoticons, and punctuation. It is included in the Natural Language Toolkit (NLTK) library in Python and can be easily used through the `SentimentIntensityAnalyzer` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9906375",
   "metadata": {},
   "source": [
    "### Aggregate and preprocess news data for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca0e200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated news written to ../data/nvda_aggregated_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Aggregate News\n",
    "\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def aggregate_news_to_trading_days(news_path=\"../data/nvda_news.csv\",\n",
    "                                   prices_path=\"../data/nvda_open_prices.csv\",\n",
    "                                   output_path=\"../data/nvda_aggregated_news.csv\"):\n",
    "    \"\"\"\n",
    "    Aggregate news from non-trading days to the next trading day.\n",
    "    Args:\n",
    "        news_path (str): path to raw news file with date and JSON-encoded headlines/summaries\n",
    "        prices_path (str): path to CSV file containing dates of trading days\n",
    "        output_path (str): path to save the aggregated output file\n",
    "    \"\"\"\n",
    "\n",
    "    # load all trading days into a set for quick look up\n",
    "    with open(prices_path, mode=\"r\", encoding=\"utf-8\") as prices_file:\n",
    "        reader = csv.reader(prices_file)\n",
    "        next(reader)  # skip the header row\n",
    "        trading_days = set(row[0] for row in reader)\n",
    "\n",
    "    # ensure dates are in chronological order\n",
    "    trading_days = sorted(trading_days)\n",
    "\n",
    "    # load news data and group headlines/summaries by date\n",
    "    news_by_date = {}\n",
    "    with open(news_path, mode=\"r\", encoding=\"utf-8\") as news_file:\n",
    "        reader = csv.DictReader(news_file)\n",
    "        for row in reader:\n",
    "            date = row[\"date\"]\n",
    "            try:\n",
    "                content_list = json.loads(row[\"content\"])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Invalid JSON content on {date}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            news_by_date.setdefault(date, []).extend(content_list)\n",
    "\n",
    "    # aggregate news from non-trading days to the next trading days\n",
    "    aggregated_news = {}\n",
    "    buffer = []\n",
    "\n",
    "    # establish the date range to process\n",
    "    current_date = min(datetime.strptime(d, \"%Y-%m-%d\") for d in news_by_date.keys())\n",
    "    max_date = max(datetime.strptime(d, \"%Y-%m-%d\") for d in news_by_date.keys())\n",
    "\n",
    "    while current_date <= max_date:\n",
    "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # accumulate news for each date, if available\n",
    "        if date_str in news_by_date:\n",
    "            buffer.extend(news_by_date[date_str])\n",
    "\n",
    "        # on a trading day, flush accumlated news into the final dictionary\n",
    "        if date_str in trading_days:\n",
    "            aggregated_news[date_str] = list(buffer)\n",
    "            buffer.clear()\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # write aggregated results to CSV\n",
    "    with open(output_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        fieldnames = [\"date\", \"content\"]\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for date, texts in aggregated_news.items():\n",
    "            writer.writerow({\n",
    "                \"date\": date,\n",
    "                \"content\": json.dumps(texts)  # save list back as JSON string for storage\n",
    "            })\n",
    "\n",
    "    print(f\"Aggregated news written to {output_path}\")\n",
    "\n",
    "# execute the aggregation function\n",
    "aggregate_news_to_trading_days()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec969bbe",
   "metadata": {},
   "source": [
    "### Perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# download VADER lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eacc745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sentiment scores for 37 days to ../data/nvda_sentiment_scores.csv\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment_vader(input_path=\"../data/nvda_aggregated_news.csv\",\n",
    "                            output_path=\"../data/nvda_sentiment_scores.csv\"):\n",
    "    \"\"\"\n",
    "    Compute daily sentiment scores using VADER and saves average scores per day.\n",
    "    Args:\n",
    "        input_path (str): path to the aggregated news file\n",
    "        output_path (str): path to save the daily sentiment scores\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "\n",
    "    with open(input_path, mode=\"r\", encoding=\"utf-8\") as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "\n",
    "        for row in reader:\n",
    "            date = row[\"date\"]\n",
    "\n",
    "            # load and clean the news text content\n",
    "            try:\n",
    "                texts = json.loads(row[\"content\"])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping malformed JSON for {date}\")\n",
    "                continue\n",
    "\n",
    "            if not texts:\n",
    "                continue  # skip if no content\n",
    "            \n",
    "            # analyze sentiment for each text using VADER\n",
    "            scores = [sid.polarity_scores(text) for text in texts]\n",
    "\n",
    "            # average the compound scores to get a daily sentiment indicator\n",
    "            avg_compound = sum(s[\"compound\"] for s in scores) / len(scores)\n",
    "\n",
    "            results.append({\n",
    "                \"date\": date,\n",
    "                \"sentiment_score\": avg_compound\n",
    "            })\n",
    "\n",
    "    # write sentiment scores to CSV\n",
    "    with open(output_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=[\"date\", \"sentiment_score\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Saved sentiment scores for {len(results)} days to {output_path}\")\n",
    "\n",
    "# run the sentiment analysis function\n",
    "analyze_sentiment_vader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
